{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date.py\t\t\t\t\t Python3数据分析与挖掘建模实战\r\n",
      "DM_Airbnb\t\t\t\t Python_cookbook\r\n",
      "environment.yml\t\t\t\t README.md\r\n",
      "Hands-on_ML_with_sklearn_and_tensorflow  Sklearn\r\n",
      "HR.csv\t\t\t\t\t untitled\r\n",
      "img\t\t\t\t\t Untitled1.ipynb\r\n",
      "knn_clf\t\t\t\t\t Untitled2.ipynb\r\n",
      "Matplotlib\t\t\t\t Untitled.ipynb\r\n",
      "MLDemo.ipynb\t\t\t\t 未命名\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "#sl:satisfaction_level--False:MinMaxScaler,True:StandardScaler\n",
    "#le:last_evaluation--False:MinMaxScaler,True:StandardScaler\n",
    "#npr:number_project--False:MinMaxScaler,True:StandardScaler\n",
    "#amh:average_montly_hours--\n",
    "#tsc:time_spend_company--\n",
    "#wa:Work_accident--\n",
    "#pl5:promotion_last_5years--\n",
    "\n",
    "#dp:department--False:LabelEncoding,True:OneHotEncoding\n",
    "#slr:salary--\n",
    "def hr_preprocessing(sl=False,le=False,npr=False,\n",
    "                     amh=False,tsc=False,wa=False,pl5=False,dp=False,slr=False,\n",
    "                     lower_d=False,ld_n=1):\n",
    "    df=pd.read_csv('./HR.csv')\n",
    "    \n",
    "    #2. 清洗数据\n",
    "    df=df.dropna(subset=['satisfaction_level','last_evaluation'])\n",
    "    df=df[df['satisfaction_level']<=1][df['salary']!='nme']\n",
    "    df=df.rename(columns={'sales':'department'})\n",
    "    #1. 标注\n",
    "    label=df[\"left\"]\n",
    "    df=df.drop(\"left\",axis=1)\n",
    "    #3. 特征选择\n",
    "    #4. 特征处理\n",
    "    scaler_lst=[sl,le,npr,amh,tsc,wa,pl5]\n",
    "    column_lst=['satisfaction_level','last_evaluation','number_project',\n",
    "                'average_montly_hours','time_spend_company','Work_accident','promotion_last_5years']\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            df[column_lst[i]]=MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1,-1)[0]\n",
    "        else:\n",
    "            df[column_lst[i]]=StandardScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1,-1)[0]\n",
    "            \n",
    "    scaler_lst=[slr,dp]\n",
    "    column_lst=['salary','department']\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            if column_lst[i]==\"salary\":\n",
    "                df[column_lst[i]]=[map_salary(s) for s in df[\"salary\"].values]\n",
    "            else:\n",
    "                df[column_lst[i]]=LabelEncoder().fit_transform(df[column_lst[i]])\n",
    "            df[column_lst[i]]=MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1,-1)[0]\n",
    "        else:\n",
    "            df=pd.get_dummies(df,columns=[column_lst[i]])\n",
    "    \n",
    "    if lower_d:\n",
    "        #return LinearDiscriminantAnalysis(n_components=ld_n)\n",
    "        return PCA(n_components=ld_n).fit_transform(df.values),label\n",
    "    return df,label\n",
    "d=dict([(\"low\",0),('medium',1),('high',2)])\n",
    "def map_salary(s):\n",
    "    return d.get(s,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr_modeling(features,label):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    f_v=features.values\n",
    "    l_v=label.values\n",
    "    X_tt,X_validation,Y_tt,Y_validation=train_test_split(f_v,l_v,test_size=0.2)\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(X_tt,Y_tt,test_size=0.25)\n",
    "    print(len(X_train),len(X_validation),len(X_test))\n",
    "    \n",
    "    #KNN\n",
    "    from sklearn.neighbors import NearestNeighbors,KNeighborsClassifier\n",
    "    knn_clf=KNeighborsClassifier(n_neighbors=3)\n",
    "    knn_clf_n5=KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_clf.fit(X_train,Y_train)\n",
    "    knn_clf_n5.fit(X_train,Y_train)\n",
    "    Y_pred=knn_clf.predict(X_validation)\n",
    "    Y_pred_n5=knn_clf_n5.predict(X_validation)\n",
    "    from sklearn.metrics import accuracy_score,recall_score,f1_score\n",
    "    print(\"验证集\")\n",
    "    print(\"ACC:\",accuracy_score(Y_validation,Y_pred))\n",
    "    print(\"REC:\",recall_score(Y_validation,Y_pred))\n",
    "    print(\"F-Score:\",f1_score(Y_validation,Y_pred))\n",
    "    print(\"--n=5---\")\n",
    "    print(\"ACC:\",accuracy_score(Y_validation,Y_pred_n5))\n",
    "    print(\"REC:\",recall_score(Y_validation,Y_pred_n5))\n",
    "    print(\"F-Score:\",f1_score(Y_validation,Y_pred_n5))\n",
    "    \n",
    "    #用测试集衡量\n",
    "    Y_pred_test=knn_clf.predict(X_test)\n",
    "    print(\"测试得分\")\n",
    "    print(\"ACC:\",accuracy_score(Y_test,Y_pred_test))\n",
    "    print(\"REC:\",recall_score(Y_test,Y_pred_test))\n",
    "    print(\"F-Score:\",f1_score(Y_test,Y_pred_test))\n",
    "    \n",
    "    #模型存储\n",
    "    from sklearn.externals import joblib\n",
    "    joblib.dump(knn_clf,\"knn_clf\") #保存\n",
    "    #knn_clf=joblib.load(\"knn_clf\") #使用时再次加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999 3000 3000\n",
      "验证集\n",
      "ACC: 0.9493333333333334\n",
      "REC: 0.9088397790055248\n",
      "F-Score: 0.896457765667575\n",
      "--n=5---\n",
      "ACC: 0.953\n",
      "REC: 0.9060773480662984\n",
      "F-Score: 0.9029593943565039\n",
      "测试得分\n",
      "ACC: 0.9516666666666667\n",
      "REC: 0.9118065433854907\n",
      "F-Score: 0.8983882270497547\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    features,label=hr_preprocessing()\n",
    "    hr_modeling(features,label)\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "features,label=hr_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.318681</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285047</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.593458</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294393</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0            0.318681         0.265625             0.0              0.285047   \n",
       "1            0.780220         0.781250             0.6              0.775701   \n",
       "2            0.021978         0.812500             1.0              0.822430   \n",
       "3            0.692308         0.796875             0.6              0.593458   \n",
       "4            0.307692         0.250000             0.0              0.294393   \n",
       "\n",
       "   time_spend_company  Work_accident  promotion_last_5years  department  \\\n",
       "0               0.125            0.0                    0.0    0.777778   \n",
       "1               0.500            0.0                    0.0    0.777778   \n",
       "2               0.250            0.0                    0.0    0.777778   \n",
       "3               0.375            0.0                    0.0    0.777778   \n",
       "4               0.125            0.0                    0.0    0.777778   \n",
       "\n",
       "   salary  \n",
       "0     0.0  \n",
       "1     0.5  \n",
       "2     0.5  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_v=features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_v=label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"activation_25\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"activation_25\".\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model cannot be compiled because it has no loss to optimize.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-220f9886905d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mean_squared_error\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#mdl.fit(X_train,np.array([[0,1] if i ==1 else [1,0] for i in y_train]),nb_epoch=1000,batch_size=2048)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m           raise ValueError('The model cannot be compiled '\n\u001b[0m\u001b[1;32m    628\u001b[0m                            'because it has no loss to optimize.')\n\u001b[1;32m    629\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The model cannot be compiled because it has no loss to optimize."
     ]
    }
   ],
   "source": [
    "mdl=Sequential()\n",
    "mdl.add(Dense(50,input_dim=len(f_v[0])))\n",
    "mdl.add(Activation(\"sigmoid\"))\n",
    "mdl.add(Dense(2))\n",
    "mdl.add(Activation(\"softmax\"))\n",
    "\n",
    "sgd=SGD(lr=0.05)\n",
    "\n",
    "mdl.compile(lose=\"mean_squared_error\",optimizer='adam')\n",
    "\n",
    "#mdl.fit(X_train,np.array([[0,1] if i ==1 else [1,0] for i in y_train]),nb_epoch=1000,batch_size=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt=GradientBoostingClassifier(max_depth=6,n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
